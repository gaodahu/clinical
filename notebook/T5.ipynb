{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyPKQadYIz9C",
        "outputId": "bd87c841-9b92-4abc-ba64-a3bf338c99ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHpnSPVVJTdR",
        "outputId": "d69d7956-006b-4481-8b84-02ae29c72eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFsBtWDHLVky",
        "outputId": "e2fbf5f9-9215-4b58-cb59-e318552bf20e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import pipeline\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer, BartConfig, AdamW, get_linear_schedule_with_warmup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "iXsNXkYdI2MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data = pd.read_excel(r'/content/drive/MyDrive/bart/MeQSum_ACL2019_BenAbacha_Demner-Fushman.xlsx')\n",
        "\n",
        "train_data, temp = train_test_split(data, test_size=0.2, random_state=42)\n",
        "test_data, val_data = train_test_split(temp, test_size=0.5, random_state=42)\n",
        "\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "val_data = val_data.reset_index(drop=True)\n",
        "test_data = test_data.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "jFSLRt4PI2N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class T5CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, source_col, target_col, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_col = source_col\n",
        "        self.target_col = target_col\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        source = \"summarize: \" + str(self.data[self.source_col][index])\n",
        "        target = str(self.data[self.target_col][index])\n",
        "\n",
        "        source = self.tokenizer.encode_plus(\n",
        "            source,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_tensors=\"pt\",\n",
        "             truncation=True\n",
        "        )\n",
        "\n",
        "        target = self.tokenizer.encode_plus(\n",
        "            target,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_tensors=\"pt\",\n",
        "             truncation=True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": source[\"input_ids\"].flatten(),\n",
        "            \"attention_mask\": source[\"attention_mask\"].flatten(),\n",
        "            \"labels\": target[\"input_ids\"].flatten(),\n",
        "        }"
      ],
      "metadata": {
        "id": "qpEfUtf9I2QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW, get_linear_schedule_with_warmup\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "train_dataset_t5 = T5CustomDataset(train_data, 'CHQ', 'Summary', tokenizer, 1000)\n",
        "val_dataset_t5 = T5CustomDataset(val_data, 'CHQ', 'Summary', tokenizer, 1000)\n",
        "test_dataset_t5 = T5CustomDataset(test_data, 'CHQ', 'Summary', tokenizer, 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIhWtV5fI2S5",
        "outputId": "c96beafe-955f-4a46-a9d3-d060c20af4e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "best_loss = np.inf\n",
        "best_batchsize = None\n",
        "best_epoch = None\n",
        "\n",
        "for batchsize in range(4,5):\n",
        "    torch.cuda.empty_cache()\n",
        "    train_dataloader = DataLoader(train_dataset_t5, batch_size=batchsize)\n",
        "    val_dataloader = DataLoader(val_dataset_t5, batch_size=batchsize)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "    total_steps = len(train_dataloader) * 2\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(1):\n",
        "        print(f'Epoch: {epoch+1}')\n",
        "\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for batch in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "        # Validation Phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "        print(f'Validation Loss: {avg_val_loss}')\n",
        "\n",
        "        if avg_val_loss < best_loss:\n",
        "            best_loss = avg_val_loss\n",
        "            best_batchsize = batchsize\n",
        "            best_epoch = epoch + 1\n",
        "            model_path = \"/content/drive/MyDrive/t5/best_model\"\n",
        "            model.save_pretrained(model_path)\n",
        "            print(f'Saving model at epoch {best_epoch} with validation loss of {best_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHSzhmU8I2U4",
        "outputId": "68277c5f-c46d-4c30-f91a-d30f7ac3f25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Validation Loss: 0.808543880879879\n",
            "Saving model at epoch 1 with validation loss of 0.809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/t5/best_model\"\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
        "test_dataset_t5 = T5CustomDataset(test_data, 'CHQ', 'Summary', tokenizer, 1000)\n",
        "test_dataloader = DataLoader(test_dataset_t5, batch_size=4)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "predictions = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    input_ids = batch[\"input_ids\"].to(device)\n",
        "    attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in outputs]\n",
        "    predictions.extend(preds)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_GjzTYjgNzQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wetyMRUUN5Xq",
        "outputId": "41d191e7-7937-4e6b-a58a-4f6be3a7f9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i have been transfusing every 22 days . i heard about a tablet', 'i have giant cell arteritis. on steroids. lost taste . i', 'shingles MESSAGE: I am having symptoms of shingles, no rash or blister', 'my grandson has contracted Rubella . he has had at least one of the vaccine', 'Ochoa syndrome MESSAGE: Where could I find more information about the rare disease', 'HYPOMATURATION TYPE, IIA2 I have 2 other daughters and', 'if you have any questions, please contact me .', 'garcinia cambodia is a plant that promotes the extract of this plant', 'a friend is 35 and his sugar level is around 100 or 120 . he tests', 'i need it fixed . it has been broken for 3 years .', 'my left hand has not been moving like it should MESSAGE . my arm itself seems', 'lipoma of forearm MESSAGE has returned .', 'starch is the source of starch . is it safe for someone with Celiac', 'clonidine is a drug that is not prescribed for a three year old female', 'chronic myeloid leukemia (CML) is a chronic myeloid le', 'angioedema is a heritary angioedema .', \"CDC has not found this information on a patient's immunity .\", \"my son has cushing's syndrome . his urine test showed 21.6H n\", 'esophygeal candida was diagnosed with Candida in my eso', 'a tall girl wants to undergo leg shortening sugery of 2 inches . it', 'my brother is getting tested for factor five because his daughter was tested . her mother said to', 'transderm Scop patch (Placement options) is a hairless site', \"drop foot hasn't come back yet . it has been four months since surgery\", 'recently I have been self induced vomiting . I know that Petechiae can be', 'pitting edema is a common condition in the skin .', 'loss of ear pressure is possible .', 'my brother has MS and its so upsetting to see him slowing down .', 'bruxism may be a result of tension or anxiety, but why that particular', 'ClinicalTrials.gov - general complaint MESSAGE: I HAVE CRONIC P', 'Tailbone trauma - aftercare I read the article . what could cause this?', 'Humalog remains active for about 4 hours . is this reasonable?', 'a rare illness called pallido ponto nigral degeneration is called pallid', 'phenobabiral is a phenobarbital medication that is toxic', 'i went through the HEP C Treatment using Ribavirin and Interferon', 'foreskin MESSAGE: when will stem cell be able to regrow for', 'GM 1 is a drug that could help his son, or at least prolong life', '\"the elderly\" should be able to use lower dosages of medications .', 'wolfram syndrome is a 46 yr old autistic male .', \"Whipple's Disease MESSAGE: Your information about it says that it is fatal\", 'buzzing in my both has been started from last 3 year . buzzing in my both', 'microfracture surgery is not prescribed and I was allowed to walk with no crutches for', 'dob-[DATE] was diagnosed with adrenal hyperplasia four days', 'if I drank some red wine, it would be no more than 1 glass or', 'body Lice MESSAGE: How do I get rid of these bugs?', 'insurance does not cover cross linking procedure because it is not FDA approved . how long will it', \"how do I know if the cause why my penis didn't grow up to\", 'he said he will take whatever . he is not on any medication, not', \"thrush Article . Weather it can happen or can't it should be told somewhere\", 'questions about the effect of L-Leucine on the effect of treat cancer?', 'swab test revealed I have serratia marcescens . scar', 'clinicalTrials.gov - Question - general information . my husband has both.', \"HOWDY YALL I'M [NAME] &I, AT [LO\", 'paim MESSAGE: my health care provider has done nothing for but give me shots and', 'bad breath can make me sick and others sick . I need advice as to what I need', 'fibroadenomas are a fibroadenomas . taking medicine', 'my husband has been detected an insulinoma . he has been diagnosed with an', 'my daughter is 6 years old she is suffering from microcytic anemia for last three', 'my daughter have Distal renal tubular acidosis . we are from Mexico,', 'my brother has multiple tumors in brain and spine . after surgery his right eyesight has', 'stiff person syndrome is a condition that causes severe cramps in my feet', 'I am 64 yrs old and a type II diabetic . I walk', 'my right shoulder is getting pain and my right hand is not moving up and back freely .', 'i want to know the cure to Adenomyosis .', 'diabetic since last 18 years and present it is 6.6 . daily it varies from', 'clinicalTrials.gov - Question - general information . a relative of mine', 'my left joint is completely worn out .', 'cant use site.com .', 'vamousse head lice treatment labe claims \"Kills 100% lice and eggs\" the', 'mrs. mrs. mrs. mrs', 'i wear a cochlear implant ,hearing aid, for 14', 'my father was given coal oil when he was sick with a cold or flu .', 'trauma such as neck injury, torn ligament, etc. can worsen McAr', 'geriatric psychiatrist in sun city west, AZ is looking for a psychiatrist', 'vagual nerve stimulation and depression have suffered for many years complicated by frequent migraines .', 'my dear friend [NAME], 52 years, [LOCATION], recently had both legs', 'my husband had a simple retropubic prostectomy 6 weeks ago . he can', \"TMAU is a 'sudden' and 'sud\", 'blood tests showed very low number of blood platelets (16,100) no cancerous cells,', 'i have an irresistible fungal on my leg and i have treated it', 'mr vaccine covers mumps, measles, rubella, mea', 'Beckwith-Wieddeman syndrome is a specific disorder .', 'chemo for breast cancer is a problem in her mouth . she has developed', 'pediatrician prescribed 1/4 of 250mg tablet once a week . pharmacist thought 3/4', 'erection problems are common in the mornings . if you have any', 'pregabalin has peripheral neuropathy but not diabetes . i have had numerous tests', 'pseudogout is a condition that may cause pseudogout . supplemental calcium may', 'ks MESSAGE: hi doctor my name is [NAME] m from', 'kidney transplant was at [LOCATION] in [LOCATION] in [LOC', 'a 6 months old girl is unable to digest any formula milk or milk products .', 'my father (age 60) have experienced a loss of speaking volume . we consult two', 'Macular Degeneration MESSAGE: Can you tell me who can answer the Question: I', 'can drug remove growth on the neck? and in how many months?', 'terbanfine, fuschin,ampiclus beecham vitamin \"c\"', 'shingles MESSAGE: I work at the airport and I am in contact with hundreds of', 'my son is ok after having anti biotics . he has a son', 'my baby has ocular albinism . can you please help me or suggest any', 'can I take zinc and zinc citrate at the same time?', 'thalamic lacunar strokes are a stroke that is a stroke that', 'apremilast ingredient may affect my cielca disease . apremila', 'plantar fasiciitis is more likely to be aggravated by weight']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YG-ErRSCfh1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "reference_summaries = test_data['Summary'].tolist()\n",
        "from rouge import Rouge\n",
        "\n",
        "rouge = Rouge()\n",
        "rouge_l_scores = rouge.get_scores(predictions, reference_summaries, avg=True)['rouge-l']\n",
        "\n",
        "print(\"ROUGE-L Scores:\", rouge_l_scores)\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "# Tokenize the reference summaries and predictions\n",
        "tokenized_reference_summaries = [word_tokenize(ref) for ref in reference_summaries]\n",
        "tokenized_predictions = [word_tokenize(pred) for pred in predictions]\n",
        "\n",
        "# Compute METEOR scores\n",
        "meteor_scores = [meteor_score([ref], pred) for ref, pred in zip(tokenized_reference_summaries, tokenized_predictions)]\n",
        "avg_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
        "\n",
        "print(\"Average METEOR Score:\", avg_meteor_score)\n",
        "\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Format the reference summaries for use with nltk's corpus_bleu\n",
        "references = [[ref.split()] for ref in reference_summaries]\n",
        "# Tokenize the generated predictions\n",
        "candidates = [pred.split() for pred in predictions]\n",
        "\n",
        "bleu_score = corpus_bleu(references, candidates)\n",
        "\n",
        "print(\"BLEU Score:\", bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dDSXZ3XI2XH",
        "outputId": "3f0804b0-1460-455e-fa0a-0225ff83053d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-L Scores: {'r': 0.11463278469896113, 'p': 0.10653359140859138, 'f': 0.10544981113771486}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average METEOR Score: 0.1467251726952368\n",
            "BLEU Score: 0.021479530820022925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T8Ne16B7NyQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JMp9FUMwI2ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0FENEuKeI2cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8HT1G4c6I2eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h9cli2TfI2go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3YGI218UI2i_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}