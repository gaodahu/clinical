{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0-h133hTXwX"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes"
      ],
      "metadata": {
        "id": "yvitXeMKUl3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "dHivLt70bLLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index"
      ],
      "metadata": {
        "id": "Lvv7GSsIbf0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.llms import HuggingFaceLLM"
      ],
      "metadata": {
        "id": "q-b07Z3lbwbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from llama_index.prompts.prompts import SimpleInputPrompt\n",
        "\n",
        "system_prompt = \"You are a clinical consultant. Your goal is to answer questions as accurately as possible based on the instructions and context provided.\"\n",
        "\n",
        "query_wrapper_prompt = SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
      ],
      "metadata": {
        "id": "Q9jigfNIb30M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "HjFbr3uxxjwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "W4PMT70P8aWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -i https://test.pypi.org/simple/ bitsandbytes"
      ],
      "metadata": {
        "id": "Zv7npvmjBFAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "id": "ejlQGVIYCqQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import accelerate\n",
        "import bitsandbytes"
      ],
      "metadata": {
        "id": "m-O_f_N2GYIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=256,\n",
        "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    device_map=\"auto\",\n",
        "    # uncomment this if using CUDA to reduce memory usage\n",
        "    model_kwargs={\"torch_dtype\": torch.float16 , \"load_in_8bit\":True}\n",
        ")"
      ],
      "metadata": {
        "id": "ucHq3EYKyGsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index import LangchainEmbedding, ServiceContext\n",
        "\n",
        "embed_model = LangchainEmbedding(\n",
        "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "H6bfd-HRJEej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(\n",
        "    chunk_size=1024,\n",
        "    llm=llm,\n",
        "    embed_model=embed_model\n",
        ")"
      ],
      "metadata": {
        "id": "R74PsVFcJMmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"/content/drive/MyDrive/content/\").load_data()"
      ],
      "metadata": {
        "id": "aWoV9sPqBeFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "id": "-C0c8bOvGDkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
      ],
      "metadata": {
        "id": "FUWVN37VYqf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index"
      ],
      "metadata": {
        "id": "pzWlA0ofGMOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What are the complications of type 1 diabetes?\")"
      ],
      "metadata": {
        "id": "saUo1mfLGTHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "SDs9Ahp6Ggw8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}